services:
  # Standard VibeVoice container
  vibe:
    build: .
    container_name: vibe
    gpus: all
    ports:
      - "7860:7860"
    volumes:
      - ./outputs:/workspace/outputs
      - ./demo/voices:/workspace/demo/voices
      - ./models:/models
      - d:/omen/coqui-ai:/workspace/coqui-ai:ro  # Mount local Coqui AI
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - COQUI_TOS_AGREED=1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 4gb
    ulimits:
      memlock: -1
      stack: 67108864
    restart: unless-stopped
    stdin_open: true
    tty: true

  # Multi-Model TTS container (VibeVoice + Coqui AI)
  vibe-multimodel:
    build:
      context: .
      dockerfile: Dockerfile.multimodel
    container_name: vibe-multimodel
    gpus: all
    ports:
      - "7861:7860"  # Different port to avoid conflicts
    volumes:
      - ./outputs:/workspace/outputs
      - ./demo/voices:/workspace/demo/voices
      - ./models:/models
      - d:/omen/coqui-ai:/workspace/coqui-ai:ro  # Mount local Coqui AI
      - ./models/coqui:/workspace/models/coqui   # Coqui model cache
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - COQUI_TOS_AGREED=1
      - COQUI_TTS_CACHE_PATH=/workspace/models/coqui
      - PYTHONPATH=/workspace:/workspace/coqui-ai
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 6gb  # More memory for multi-model
    ulimits:
      memlock: -1
      stack: 67108864
    restart: unless-stopped
    stdin_open: true
    tty: true
    command: ["bash", "-lc", "lsof -ti:7860 | xargs -r kill -9; python demo/multimodel_gradio_demo.py --share --host 0.0.0.0 --port 7860"]

  # Desktop GUI container (for remote desktop access)
  vibe-desktop:
    build:
      context: .
      dockerfile: Dockerfile.multimodel
    container_name: vibe-desktop
    gpus: all
    ports:
      - "6080:6080"  # VNC web interface
      - "5900:5900"  # VNC direct access
    volumes:
      - ./outputs:/workspace/outputs
      - ./demo/voices:/workspace/demo/voices
      - ./models:/workspace/models
      - d:/omen/coqui-ai:/workspace/coqui-ai:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - DISPLAY=:1
      - VNC_PW=vibevoice
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 4gb
    ulimits:
      memlock: -1
      stack: 67108864
    restart: unless-stopped
    stdin_open: true
    tty: true
    command: ["bash", "-lc", "Xvfb :1 -screen 0 1024x768x16 & x11vnc -display :1 -nopw -listen localhost -xkb -rfbauth /etc/vnc/passwd & python desktop_gui.py"]

  # Ebook to Audiobook Converter (Python 3.13, VibeVoice only)
  vibe-ebook:
    build:
      context: .
      dockerfile: Dockerfile.ebook
    container_name: vibe-ebook
    gpus: all
    ports:
      - "7862:7862"
    volumes:
      - ./outputs:/workspace/outputs
      - ./ebook_input:/workspace/ebook_input
      - ./ebook_output:/workspace/ebook_output
      - ./demo/voices:/workspace/demo/voices
      - ./models:/workspace/models
      - d:/omen/coqui-ai:/workspace/coqui-ai:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - COQUI_TOS_AGREED=1
      - PYTHONPATH=/workspace:/workspace/coqui-ai
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=7862
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 6gb
    ulimits:
      memlock: -1
      stack: 67108864
    restart: unless-stopped
    stdin_open: true
    tty: true
    command: ["bash", "-lc", "lsof -ti:7862 | xargs -r kill -9; python ebook_gui.py"]

  # Ebook to Audiobook Converter with Coqui AI (Python 3.11)
  vibe-ebook-py311:
    build:
      context: .
      dockerfile: Dockerfile.ebook-py311
    container_name: vibe-ebook-py311
    gpus: all
    ports:
      - "7863:7863"
    volumes:
      - ./outputs:/workspace/outputs
      - ./ebook_input:/workspace/ebook_input
      - ./ebook_output:/workspace/ebook_output
      - ./demo/voices:/workspace/demo/voices
      - ./models:/workspace/models
      - ./models/coqui:/workspace/models/coqui
      - d:/omen/coqui-ai:/workspace/coqui-ai:ro
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_VISIBLE_DEVICES=0
      - COQUI_TOS_AGREED=1
      - TTS_CACHE_PATH=/workspace/models/coqui
      - PYTHONPATH=/workspace:/workspace/coqui-ai
      - GRADIO_SERVER_NAME=0.0.0.0
      - GRADIO_SERVER_PORT=7863
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    shm_size: 8gb  # More memory for Coqui models
    ulimits:
      memlock: -1
      stack: 67108864
    restart: unless-stopped
    stdin_open: true
    tty: true
    command: ["/workspace/start_ebook_py311.sh"]
